# ğŸœ† The Deep Prospecting Engine

A local, agentic application that leverages Gemini Deep Research to identify high-value AI/ML sales opportunities for specific clients, utilizing "silent" historical memory to improve recommendations over time.

## Architecture

```
User/UI â†’ Input Processor â†’ Gemini Deep Research API
                â†“
         Context Merger â† ChromaDB (Similar Verticals + Plays)
                â†“
         Competitor Scout (Case Studies)
                â†“
         Id8 Iteration Loop
           â”œâ”€â”€ Divergent (10+ Ideas)
           â””â”€â”€ Convergent Refiner (Top 3)
                â†“
         Asset Generator (Pellera Voice)
                â†“
         Markdown Files (One-Pagers + Strategic Plans)
                â†“
         ChromaStore â†’ ChromaDB (Feedback Loop)
```

## Stack

- **Orchestration:** LangGraph
- **LLM:** Google Gemini (Deep Research API)
- **Vector DB:** ChromaDB
- **UI:** Streamlit
- **Language:** Python 3.11+
- **Deployment:** Docker

## Quick Start

```bash
# Clone
git clone https://github.com/aquaregiaswarm-blip/deep-prospecting-engine.git
cd deep-prospecting-engine

# Setup
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

# Configure
cp .env.example .env
# Edit .env with your GEMINI_API_KEY

# Run
streamlit run src/app.py

# Test
pytest tests/ -v
```

## Project Structure

```
deep-prospecting-engine/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py                  # Streamlit UI
â”‚   â”œâ”€â”€ graph/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ state.py            # LangGraph state schema
â”‚   â”‚   â”œâ”€â”€ nodes/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ input_processor.py
â”‚   â”‚   â”‚   â”œâ”€â”€ deep_research.py
â”‚   â”‚   â”‚   â”œâ”€â”€ context_merger.py
â”‚   â”‚   â”‚   â”œâ”€â”€ competitor_scout.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ideation.py
â”‚   â”‚   â”‚   â””â”€â”€ asset_generator.py
â”‚   â”‚   â””â”€â”€ workflow.py         # LangGraph workflow definition
â”‚   â”œâ”€â”€ memory/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ chroma_query.py
â”‚   â”‚   â””â”€â”€ chroma_store.py
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_research.py
â”‚   â”‚   â”œâ”€â”€ pellera_voice.py
â”‚   â”‚   â””â”€â”€ ideation.py
â”‚   â””â”€â”€ config.py               # Settings & env management
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_input_processor.py
â”‚   â”œâ”€â”€ test_deep_research.py
â”‚   â”œâ”€â”€ test_context_merger.py
â”‚   â”œâ”€â”€ test_competitor_scout.py
â”‚   â”œâ”€â”€ test_ideation.py
â”‚   â”œâ”€â”€ test_asset_generator.py
â”‚   â”œâ”€â”€ test_memory.py
â”‚   â””â”€â”€ test_workflow.py
â”œâ”€â”€ output/                     # Generated markdown files
â”œâ”€â”€ data/                       # ChromaDB persistent storage
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

## Epics

1. **Core Infrastructure & Data Ingestion** â€” Environment, UI, API integration
2. **Deep Research & Competitive Analysis** â€” Gemini research, vertical ID, competitor scouting
3. **Silent Memory (Vector Knowledge Base)** â€” ChromaDB for learning from past wins
4. **Ideation Loop ("id8")** â€” Divergent/convergent idea generation
5. **Asset Generation & Voice** â€” Pellera-voiced markdown deliverables

## License

Proprietary â€” Pellera
